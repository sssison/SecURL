{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Classifier with Wrapper-Based FS\n",
    "\n",
    "Steven Sison | March 9, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document will be used to train a model using the reduced feature set obtain by using the wrapper-based method, forward feature selection. The model will be evaluated in terms of the usual metrics (accuracy, precision, F1-score, recall) as well as the training time. The model will also be stored for future evaluation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_type</th>\n",
       "      <th>url_length</th>\n",
       "      <th>url_ip_in_domain</th>\n",
       "      <th>url_domain_entropy</th>\n",
       "      <th>url_is_digits_in_domain</th>\n",
       "      <th>url_query_length</th>\n",
       "      <th>url_number_of_parameters</th>\n",
       "      <th>url_number_of_digits</th>\n",
       "      <th>url_string_entropy</th>\n",
       "      <th>url_is_https</th>\n",
       "      <th>...</th>\n",
       "      <th>has_swf_in_string</th>\n",
       "      <th>has_cgi_in_string</th>\n",
       "      <th>has_php_in_string</th>\n",
       "      <th>has_abuse_in_string</th>\n",
       "      <th>has_admin_in_string</th>\n",
       "      <th>has_bin_in_string</th>\n",
       "      <th>has_personal_in_string</th>\n",
       "      <th>has_update_in_string</th>\n",
       "      <th>has_verification_in_string</th>\n",
       "      <th>url_scheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.169925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2.807355</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.079143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2.921928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.708093</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>2.896292</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4.660343</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>3.405822</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>4.980518</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_type  url_length  url_ip_in_domain  url_domain_entropy  \\\n",
       "0         1          16                 0            3.169925   \n",
       "1         0          35                 0            2.807355   \n",
       "2         0          31                 0            2.921928   \n",
       "3         1          88                 0            2.896292   \n",
       "4         1         235                 0            3.405822   \n",
       "\n",
       "   url_is_digits_in_domain  url_query_length  url_number_of_parameters  \\\n",
       "0                        0                 0                         0   \n",
       "1                        1                 0                         0   \n",
       "2                        0                 0                         0   \n",
       "3                        0                49                         4   \n",
       "4                        0               194                         3   \n",
       "\n",
       "   url_number_of_digits  url_string_entropy  url_is_https  ...  \\\n",
       "0                     0            3.375000             0  ...   \n",
       "1                     1            4.079143             0  ...   \n",
       "2                     1            3.708093             0  ...   \n",
       "3                     7            4.660343             0  ...   \n",
       "4                    22            4.980518             0  ...   \n",
       "\n",
       "   has_swf_in_string  has_cgi_in_string  has_php_in_string  \\\n",
       "0                  0                  0                  0   \n",
       "1                  0                  0                  0   \n",
       "2                  0                  0                  0   \n",
       "3                  0                  0                  1   \n",
       "4                  0                  0                  1   \n",
       "\n",
       "   has_abuse_in_string  has_admin_in_string  has_bin_in_string  \\\n",
       "0                    0                    0                  0   \n",
       "1                    0                    0                  0   \n",
       "2                    0                    0                  0   \n",
       "3                    0                    0                  0   \n",
       "4                    0                    0                  0   \n",
       "\n",
       "   has_personal_in_string  has_update_in_string  has_verification_in_string  \\\n",
       "0                       0                     0                           0   \n",
       "1                       0                     0                           0   \n",
       "2                       0                     0                           0   \n",
       "3                       0                     0                           0   \n",
       "4                       0                     0                           0   \n",
       "\n",
       "   url_scheme  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3          27  \n",
       "4          27  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd                     # For data transformation\n",
    "import numpy as numpy                   # For scientific calculations\n",
    "import seaborn as sns                   # For data visualizations\n",
    "import matplotlib.pyplot as plt         # For plotting\n",
    "import plotly.graph_objects as go       # For plotting\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from xgboost import XGBClassifier, DMatrix, train\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "dataset = pd.read_csv(\"../../../02_feature-engineering/final-datasets/binary_new_Bacud_unbalanced_lexical.csv\")      # Loading the dataset\n",
    "\n",
    "dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset.drop(columns=['url_type']), dataset['url_type'], test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"../../../02_feature-engineering/final-datasets/valid_unbalanced_with_lexical.csv\")\n",
    "valid.head()\n",
    "\n",
    "y_valid = valid['url_type']\n",
    "X_valid = valid.drop(columns=['url_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing (Balancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url_type\n",
       "0    724778\n",
       "1    380244\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['url_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Removing Unnecessary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>url_domain_entropy</th>\n",
       "      <th>url_is_digits_in_domain</th>\n",
       "      <th>url_number_of_parameters</th>\n",
       "      <th>url_number_of_digits</th>\n",
       "      <th>url_string_entropy</th>\n",
       "      <th>url_path_length</th>\n",
       "      <th>url_host_length</th>\n",
       "      <th>get_tld</th>\n",
       "      <th>url_domain_len</th>\n",
       "      <th>...</th>\n",
       "      <th>has_exe_in_string</th>\n",
       "      <th>has_viewerphp_in_string</th>\n",
       "      <th>has_getImageasp_in_string</th>\n",
       "      <th>has_paypal_in_string</th>\n",
       "      <th>has_dbsysphp_in_string</th>\n",
       "      <th>has_shopping_in_string</th>\n",
       "      <th>has_php_in_string</th>\n",
       "      <th>has_bin_in_string</th>\n",
       "      <th>has_personal_in_string</th>\n",
       "      <th>url_scheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165686</th>\n",
       "      <td>58</td>\n",
       "      <td>1.921928</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>4.659537</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712465</th>\n",
       "      <td>76</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.626107</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335773</th>\n",
       "      <td>133</td>\n",
       "      <td>2.664498</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4.657590</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>332</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533676</th>\n",
       "      <td>30</td>\n",
       "      <td>3.381580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.989898</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>320</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642230</th>\n",
       "      <td>44</td>\n",
       "      <td>2.699514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.772185</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        url_length  url_domain_entropy  url_is_digits_in_domain  \\\n",
       "165686          58            1.921928                        0   \n",
       "712465          76            2.750000                        0   \n",
       "335773         133            2.664498                        0   \n",
       "533676          30            3.381580                        0   \n",
       "642230          44            2.699514                        0   \n",
       "\n",
       "        url_number_of_parameters  url_number_of_digits  url_string_entropy  \\\n",
       "165686                         1                    14            4.659537   \n",
       "712465                         0                    10            4.626107   \n",
       "335773                         7                     5            4.657590   \n",
       "533676                         0                     0            3.989898   \n",
       "642230                         0                     0            3.772185   \n",
       "\n",
       "        url_path_length  url_host_length  get_tld  url_domain_len  ...  \\\n",
       "165686               32                0        0               5  ...   \n",
       "712465               42               26      152               8  ...   \n",
       "335773               10               21      332              14  ...   \n",
       "533676                1               21      320              17  ...   \n",
       "642230               44                0      202              14  ...   \n",
       "\n",
       "        has_exe_in_string  has_viewerphp_in_string  has_getImageasp_in_string  \\\n",
       "165686                  0                        0                          0   \n",
       "712465                  0                        0                          0   \n",
       "335773                  0                        0                          0   \n",
       "533676                  0                        0                          0   \n",
       "642230                  0                        0                          0   \n",
       "\n",
       "        has_paypal_in_string  has_dbsysphp_in_string  has_shopping_in_string  \\\n",
       "165686                     0                       0                       0   \n",
       "712465                     0                       0                       0   \n",
       "335773                     0                       0                       0   \n",
       "533676                     0                       0                       0   \n",
       "642230                     0                       0                       0   \n",
       "\n",
       "        has_php_in_string  has_bin_in_string  has_personal_in_string  \\\n",
       "165686                  0                  0                       0   \n",
       "712465                  0                  0                       0   \n",
       "335773                  1                  0                       0   \n",
       "533676                  0                  0                       0   \n",
       "642230                  0                  0                       0   \n",
       "\n",
       "        url_scheme  \n",
       "165686           0  \n",
       "712465           2  \n",
       "335773          27  \n",
       "533676          28  \n",
       "642230           0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features_wrapper_33 = ['url_length',\n",
    " 'url_domain_entropy',\n",
    " 'url_is_digits_in_domain',\n",
    " 'url_number_of_parameters',\n",
    " 'url_number_of_digits',\n",
    " 'url_string_entropy',\n",
    " 'url_path_length',\n",
    " 'url_host_length',\n",
    " 'get_tld',\n",
    " 'url_domain_len',\n",
    " 'url_num_subdomain',\n",
    " 'url_number_of_fragments',\n",
    " 'url_is_encoded',\n",
    " 'url_number_of_letters',\n",
    " 'url_num_periods',\n",
    " 'url_num_of_hyphens',\n",
    " 'url_num_underscore',\n",
    " 'url_num_forward_slash',\n",
    " 'url_num_semicolon',\n",
    " 'url_num_mod_sign',\n",
    " 'has_login_in_string',\n",
    " 'has_signin_in_string',\n",
    " 'has_logon_in_string',\n",
    " 'has_loginasp_in_string',\n",
    " 'has_exe_in_string',\n",
    " 'has_viewerphp_in_string',\n",
    " 'has_getImageasp_in_string',\n",
    " 'has_paypal_in_string',\n",
    " 'has_dbsysphp_in_string',\n",
    " 'has_shopping_in_string',\n",
    " 'has_php_in_string',\n",
    " 'has_bin_in_string',\n",
    " 'has_personal_in_string',\n",
    " 'url_scheme'\n",
    " ]\n",
    "\n",
    "important_features_wrapper_12 = ['url_domain_entropy', \n",
    "                              'url_number_of_parameters', \n",
    "                              'url_number_of_digits', \n",
    "                              'url_path_length', \n",
    "                              'url_host_length', \n",
    "                              'get_tld', \n",
    "                              'url_domain_len', \n",
    "                              'url_num_subdomain', \n",
    "                              'url_number_of_letters', \n",
    "                              'url_num_periods', \n",
    "                              'url_num_of_hyphens', \n",
    "                              'url_num_forward_slash', \n",
    "                              'url_num_semicolon', \n",
    "                              'has_login_in_string', \n",
    "                              'has_exe_in_string', \n",
    "                              'has_php_in_string', \n",
    "                              'url_scheme']\n",
    "\n",
    "X_test_12 = x_test[important_features_wrapper_12]\n",
    "X_train_12 = x_train[important_features_wrapper_12]\n",
    "\n",
    "X_test_33 = x_test[important_features_wrapper_33]\n",
    "X_train_33 = x_train[important_features_wrapper_33]\n",
    "X_valid_33 = X_valid[important_features_wrapper_33]\n",
    "\n",
    "X_test_33.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12 Features (Purely Lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def objective_12(trial):\\n    # Define the search space for hyperparameters\\n    param = {\\n        \\'objective\\': \\'binary:hinge\\',\\n        \\'eval_metric\\': \\'error\\',\\n        \\'eta\\': trial.suggest_float(\\'eta\\', 0.01, 0.3),\\n        \\'n_estimators\\': 100000, # Fix the boosting round and use early stopping\\n        \\'max_depth\\': trial.suggest_int(\\'max_depth\\', 3, 10),\\n        \\'subsample\\': trial.suggest_float(\\'subsample\\', 0.5, 1.0),\\n        \\'colsample_bytree\\': trial.suggest_float(\\'colsample_bytree\\', 0.5, 1.0),\\n        \\'gamma\\': trial.suggest_float(\\'gamma\\', 0.0, 10.0),\\n        \\'min_child_weight\\': trial.suggest_float(\\'min_child_weight\\', 0.1, 10.0),\\n        \\'lambda\\': trial.suggest_float(\\'lambda\\', 0.1, 10.0),\\n        \\'alpha\\': trial.suggest_float(\\'alpha\\', 0.0, 10.0),\\n    }\\n    \\n    # Split the data into further training and validation sets (three sets are preferable)\\n    train_data, valid_data, train_target, valid_target = train_test_split(X_train_12, y_train, test_size=0.2, random_state=42)\\n    \\n    # Convert the data into DMatrix format\\n    dtrain = DMatrix(train_data, label=train_target)\\n    dvalid = DMatrix(valid_data, label=valid_target)\\n    \\n    # Define the pruning callback for early stopping\\n    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \\'validation-error\\')\\n    \\n    # Train the model with early stopping\\n    model = train(param, dtrain, num_boost_round=100000, evals=[(dvalid, \\'validation\\')], early_stopping_rounds=100, callbacks=[pruning_callback])\\n    \\n    # Make predictions on the test set\\n    dtest = DMatrix(valid_data)\\n    y_pred = model.predict(dtest)\\n    \\n    # Calculate the root mean squared error\\n    error = mean_squared_error(valid_target, y_pred, squared=False)\\n    \\n    return error\\n\\n# Create an Optuna study and optimize the objective function\\nstudy_12 = optuna.create_study(direction=\\'minimize\\')\\nstudy_12.optimize(objective_12, n_trials=100) # Control the number of trials\\n\\n# Print the best hyperparameters and the best RMSE\\nbest_params_12 = study_12.best_params\\nbest_error = study_12.best_value\\nprint(\"Best Hyperparameters (12 Features): \", best_params_12)\\nprint(\"Best Error (12 Features): \", best_error)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error # or any other metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "'''def objective_12(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    param = {\n",
    "        'objective': 'binary:hinge',\n",
    "        'eval_metric': 'error',\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.3),\n",
    "        'n_estimators': 100000, # Fix the boosting round and use early stopping\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 10.0),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 10.0),\n",
    "        'lambda': trial.suggest_float('lambda', 0.1, 10.0),\n",
    "        'alpha': trial.suggest_float('alpha', 0.0, 10.0),\n",
    "    }\n",
    "    \n",
    "    # Split the data into further training and validation sets (three sets are preferable)\n",
    "    train_data, valid_data, train_target, valid_target = train_test_split(X_train_12, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convert the data into DMatrix format\n",
    "    dtrain = DMatrix(train_data, label=train_target)\n",
    "    dvalid = DMatrix(valid_data, label=valid_target)\n",
    "    \n",
    "    # Define the pruning callback for early stopping\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, 'validation-error')\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model = train(param, dtrain, num_boost_round=100000, evals=[(dvalid, 'validation')], early_stopping_rounds=100, callbacks=[pruning_callback])\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    dtest = DMatrix(valid_data)\n",
    "    y_pred = model.predict(dtest)\n",
    "    \n",
    "    # Calculate the root mean squared error\n",
    "    error = mean_squared_error(valid_target, y_pred, squared=False)\n",
    "    \n",
    "    return error\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study_12 = optuna.create_study(direction='minimize')\n",
    "study_12.optimize(objective_12, n_trials=100) # Control the number of trials\n",
    "\n",
    "# Print the best hyperparameters and the best RMSE\n",
    "best_params_12 = study_12.best_params\n",
    "best_error = study_12.best_value\n",
    "print(\"Best Hyperparameters (12 Features): \", best_params_12)\n",
    "print(\"Best Error (12 Features): \", best_error)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 33 Features (Purely Lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:53:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07f6e447eee219473-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-error:0.65653\n",
      "[1]\tvalidation-error:0.65653\n",
      "[2]\tvalidation-error:0.65653\n",
      "[3]\tvalidation-error:0.39471\n",
      "[4]\tvalidation-error:0.18653\n",
      "[5]\tvalidation-error:0.11853\n",
      "[6]\tvalidation-error:0.09378\n",
      "[7]\tvalidation-error:0.08795\n",
      "[8]\tvalidation-error:0.07723\n",
      "[9]\tvalidation-error:0.07084\n",
      "[10]\tvalidation-error:0.06605\n",
      "[11]\tvalidation-error:0.06537\n",
      "[12]\tvalidation-error:0.06444\n",
      "[13]\tvalidation-error:0.06175\n",
      "[14]\tvalidation-error:0.06095\n",
      "[15]\tvalidation-error:0.06018\n",
      "[16]\tvalidation-error:0.05981\n",
      "[17]\tvalidation-error:0.05950\n",
      "[18]\tvalidation-error:0.05940\n",
      "[19]\tvalidation-error:0.05904\n",
      "[20]\tvalidation-error:0.05901\n",
      "[21]\tvalidation-error:0.05853\n",
      "[22]\tvalidation-error:0.05822\n",
      "[23]\tvalidation-error:0.05676\n",
      "[24]\tvalidation-error:0.05671\n",
      "[25]\tvalidation-error:0.05630\n",
      "[26]\tvalidation-error:0.05596\n",
      "[27]\tvalidation-error:0.05570\n",
      "[28]\tvalidation-error:0.05545\n",
      "[29]\tvalidation-error:0.05524\n",
      "[30]\tvalidation-error:0.05489\n",
      "[31]\tvalidation-error:0.05446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial 0 failed with parameters: {'eta': 0.15942487787595352, 'max_depth': 6, 'subsample': 0.9868074499358724, 'colsample_bytree': 0.7565282277150545, 'gamma': 1.3640586103424746, 'min_child_weight': 8.713758328180456, 'lambda': 7.558214814876345, 'alpha': 5.466847792880651} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sison\\AppData\\Local\\Temp\\ipykernel_28244\\2053542314.py\", line 29, in objective_33\n",
      "    model = train(param, dtrain, num_boost_round=100000, evals=[(dvalid, 'validation')], early_stopping_rounds=100, callbacks=[pruning_callback])\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 2050, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m study_33 \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mdisable_propagation()\n\u001b[1;32m---> 43\u001b[0m \u001b[43mstudy_33\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_33\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Control the number of trials\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters and the best RMSE\u001b[39;00m\n\u001b[0;32m     46\u001b[0m best_params_33 \u001b[38;5;241m=\u001b[39m study_33\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m, in \u001b[0;36mobjective_33\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     26\u001b[0m pruning_callback \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mintegration\u001b[38;5;241m.\u001b[39mXGBoostPruningCallback(trial, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation-error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model with early stopping\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpruning_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m     32\u001b[0m dtest \u001b[38;5;241m=\u001b[39m DMatrix(valid_data)\n",
      "File \u001b[1;32mc:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:2050\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2049\u001b[0m     _check_call(\n\u001b[1;32m-> 2050\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2053\u001b[0m     )\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2055\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective_33(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    param = {\n",
    "        'objective': 'binary:hinge',\n",
    "        'eval_metric': 'error',\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.3),\n",
    "        'n_estimators': 100000, # Fix the boosting round and use early stopping\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 10.0),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 0.1, 10.0),\n",
    "        'lambda': trial.suggest_float('lambda', 0.1, 10.0),\n",
    "        'alpha': trial.suggest_float('alpha', 0.0, 10.0),\n",
    "    }\n",
    "    \n",
    "    # Split the data into further training and validation sets (three sets are preferable)\n",
    "    train_data, valid_data, train_target, valid_target = train_test_split(X_train_33, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convert the data into DMatrix format\n",
    "    dtrain = DMatrix(train_data, label=train_target)\n",
    "    dvalid = DMatrix(valid_data, label=valid_target)\n",
    "    \n",
    "    # Define the pruning callback for early stopping\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, 'validation-error')\n",
    "    \n",
    "    # Train the model with early stopping\n",
    "    model = train(param, dtrain, num_boost_round=100000, evals=[(dvalid, 'validation')], early_stopping_rounds=100, callbacks=[pruning_callback])\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    dtest = DMatrix(valid_data)\n",
    "    y_pred = model.predict(dtest)\n",
    "    \n",
    "    # Calculate the root mean squared error\n",
    "    error = mean_squared_error(valid_target, y_pred, squared=False)\n",
    "    \n",
    "    return error\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "study_33 = optuna.create_study(direction='minimize')\n",
    "optuna.logging.disable_propagation\n",
    "study_33.optimize(objective_33, n_trials=100) # Control the number of trials\n",
    "\n",
    "# Print the best hyperparameters and the best RMSE\n",
    "best_params_33 = study_33.best_params\n",
    "best_error_33 = study_33.best_value\n",
    "print(\"Best Hyperparameters (33 Features): \", best_params_33)\n",
    "print(\"Best Error (33 Features): \", best_error_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.24226975546058, 'max_depth': 10, 'subsample': 0.6466791951857404, 'colsample_bytree': 0.9360515577115375, 'gamma': 0.7881935821756819, 'min_child_weight': 5.796268337379454, 'lambda': 8.312555103835237, 'alpha': 2.489715207685439}\n"
     ]
    }
   ],
   "source": [
    "# print(best_params_12)\n",
    "print(best_params_33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 33 Features Done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "\n",
    "# Initialize CV\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# best_params_12['objective'] = 'binary:hinge'\n",
    "# best_params_12['eval_metric'] = 'error'\n",
    "\n",
    "best_params_33['objective'] = 'binary:hinge'\n",
    "best_params_33['eval_metric'] = 'error'\n",
    "\n",
    "# Convert the data into DMatrix format\n",
    "# dtrain_12 = DMatrix(X_train_12, label=y_train)\n",
    "# dvalid_12 = DMatrix(X_test_12, label=y_test)\n",
    "\n",
    "dtrain_33 = DMatrix(X_train_33, label=y_train)\n",
    "dvalid_33 = DMatrix(X_test_33, label=y_test)\n",
    "lexical_valid = DMatrix(X_valid_33, label = y_valid)\n",
    "\n",
    "# Train the Model\n",
    "# xgb_classifier_12 = train(best_params_12, dtrain_12, num_boost_round=3000)\n",
    "# y_pred_12 = xgb_classifier_12.predict(dvalid_12)\n",
    "\n",
    "# print(\"Model with 12 Features Done.\")\n",
    "\n",
    "xgb_classifier_33 = train(best_params_33, dtrain_33, num_boost_round=3000)\n",
    "y_pred_33 = xgb_classifier_33.predict(dvalid_33)\n",
    "y_pred_valid = xgb_classifier_33.predict(lexical_valid)\n",
    "\n",
    "print(\"Model with 33 Features Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting some stuff for concept drift\n",
    "\n",
    "# Actual Values\n",
    "y_test.to_csv(\"warm-up-actual.csv\", encoding='utf-8', index=False)\n",
    "y_valid.to_csv(\"testing-actual.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "temp_pred_test = pd.DataFrame(y_pred_33)\n",
    "temp_pred_valid = pd.DataFrame(y_pred_valid)\n",
    "\n",
    "temp_pred_test.to_csv(\"warm-up-predicted.csv\", encoding='utf-8', index=False)\n",
    "temp_pred_valid.to_csv(\"testing-predicted.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Test Evaluation -------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98    144867\n",
      "           1       0.96      0.95      0.96     76138\n",
      "\n",
      "    accuracy                           0.97    221005\n",
      "   macro avg       0.97      0.97      0.97    221005\n",
      "weighted avg       0.97      0.97      0.97    221005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(\"------------- Test Evaluation -------------\")\n",
    "# print(classification_report(y_test, y_pred_12))\n",
    "print(classification_report(y_test, y_pred_33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Practical Evaluation -------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.02      1000\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.01      1000\n",
      "   macro avg       0.50      0.01      0.01      1000\n",
      "weighted avg       1.00      0.01      0.02      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sison\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(\"------------- Practical Evaluation -------------\")\n",
    "\n",
    "print(classification_report(y_valid, y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Confusion Matrix for 12 Features\\ncm_up = confusion_matrix(y_test, y_pred_12, labels=xgb_classifier_12.classes_)\\ndisp = ConfusionMatrixDisplay(confusion_matrix = cm_up, display_labels = xgb_classifier_12.classes_)\\ndisp.plot()\\nplt.show()'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Confusion Matrix for 12 Features\n",
    "cm_up = confusion_matrix(y_test, y_pred_12, labels=xgb_classifier_12.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm_up, display_labels = xgb_classifier_12.classes_)\n",
    "disp.plot()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Cross Validation Score\\nscores = cross_val_score(XGBClassifier(**params_gbm),\\n                        X_train, y_train, scoring='accuracy', cv=cv).mean()\\n\\nprint(scores)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Cross Validation Score\n",
    "scores = cross_val_score(XGBClassifier(**params_gbm),\n",
    "                        X_train, y_train, scoring='accuracy', cv=cv).mean()\n",
    "\n",
    "print(scores)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping the model\n",
    "# joblib.dump(xgb_classifier_12, 'xgb_ffs_12.sav')\n",
    "# joblib.dump(xgb_classifier_33, 'xgb_ffs_33.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current URL: www.facebook.com/\n",
      "------------- Wrapper-Based (33 Features) -------------\n",
      "Trial 0\n",
      "Benign\n",
      "0.14897370000835508\n",
      "Trial 1\n",
      "Benign\n",
      "0.018642800045199692\n",
      "Trial 2\n",
      "Benign\n",
      "0.018542799982242286\n",
      "Trial 3\n",
      "Benign\n",
      "0.017739899980369955\n",
      "Trial 4\n",
      "Benign\n",
      "0.019178599992301315\n",
      "Trial 5\n",
      "Benign\n",
      "0.018538899952545762\n",
      "Trial 6\n",
      "Benign\n",
      "0.018301800009794533\n",
      "Trial 7\n",
      "Benign\n",
      "0.017975899972952902\n",
      "Trial 8\n",
      "Benign\n",
      "0.018234599963761866\n",
      "Trial 9\n",
      "Benign\n",
      "0.018532600020989776\n",
      "Trial 10\n",
      "Benign\n",
      "0.01923849998274818\n",
      "Trial 11\n",
      "Benign\n",
      "0.01895750005496666\n",
      "Trial 12\n",
      "Benign\n",
      "0.017861199972685426\n",
      "Trial 13\n",
      "Benign\n",
      "0.017586899979505688\n",
      "Trial 14\n",
      "Benign\n",
      "0.018745700013823807\n"
     ]
    }
   ],
   "source": [
    "import lexical_generator_12\n",
    "import lexical_generator_33\n",
    "import time\n",
    "\n",
    "'''def xgb_predict_maliciousness_12(url):\n",
    "\n",
    "    numerical_values = lexical_generator_12.lexical_generator(url)\n",
    "    # print(numerical_values)\n",
    "    numerical_values = DMatrix(numerical_values)\n",
    "\n",
    "    match xgb_classifier_12.predict(numerical_values):\n",
    "        case 0:\n",
    "            return \"Benign\"\n",
    "        case 1:\n",
    "            return \"Malware\"\n",
    "        case 2:\n",
    "            return \"Phishing\"\n",
    "        case 3:\n",
    "            return \"Defacement\"'''\n",
    "        \n",
    "def xgb_predict_maliciousness_33(url):\n",
    "\n",
    "    numerical_values = lexical_generator_33.lexical_generator(url)\n",
    "    # print(numerical_values)\n",
    "    numerical_values = DMatrix(numerical_values)\n",
    "\n",
    "    match xgb_classifier_33.predict(numerical_values):\n",
    "        case 0:\n",
    "            return \"Benign\"\n",
    "        case 1:\n",
    "            return \"Malware\"\n",
    "        case 2:\n",
    "            return \"Phishing\"\n",
    "        case 3:\n",
    "            return \"Defacement\"\n",
    "\n",
    "url = \"www.facebook.com/\"\n",
    "print(\"Current URL: \"+url)\n",
    "\n",
    "'''print(\"------------- Wrapper-Based (12 Features) -------------\")\n",
    "for i in range(15):\n",
    "    start = time.perf_counter()\n",
    "    prediction = xgb_predict_maliciousness_12(url)\n",
    "    end = time.perf_counter()\n",
    "    print(\"Trial \"+str(i))\n",
    "    print(prediction)\n",
    "    print(end-start)'''\n",
    "\n",
    "print(\"------------- Wrapper-Based (33 Features) -------------\")\n",
    "for i in range(15):\n",
    "    start = time.perf_counter()\n",
    "    prediction = xgb_predict_maliciousness_33(url)\n",
    "    end = time.perf_counter()\n",
    "    print(\"Trial \"+str(i))\n",
    "    print(prediction)\n",
    "    print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
